---
title: "Creating an AI chatbot using HuggingFace pretrained"
teaching: 15 min
exercises: 0
questions: "How to create an AI chatbot"
objectives:

keypoints:
- "HuggingFace, chatbot"
---
# 7. Creating an AI chatbot using HuggingFace pretrained in your ManeFrame or SuperPOD

## Introduction
- It can not be easier than ever to create your own AI chatbot.
- Lots of pretrained model are uploaded from big companies like Microsoft, Facebook, Google to individual users
- Many of the pretrained NLP models can be found from HuggingFace:

![image](https://user-images.githubusercontent.com/43855029/222789762-04e380d8-fa48-40be-bd53-c8402ff980a0.png)

## Download pretrained model from HuggingFace and create your own chatbot

- From the above example, you can see the pretrained model from microsoft/DialoGPT large
- You can also interact with the model via "Hosted inference API" box on the right
- However, the Cloud computing from HuggingFace sometime can be very slow, and you want to utilize the computing power resources from M2/SP
- Assuming that you already have a working conda environment in M2/SP. Let's try the following code:

```python
import transformers
nlp = transformers.pipeline("conversational",
                            model="microsoft/DialoGPT-large")

cont=1
while cont==1:
    input_text = input("Ask me a question!")
    print(nlp(transformers.Conversation(input_text), pad_token_id=57007))
    if input("Continue?").lower()=="no":
        print("Goodbye")
        break
```

## Running the model

- Save the model as chatbot_DialoGPT-large.py and we can run it:

```python
python chatbot_DialoGPT-large.py
```

Following is the inference from running the chatbot model:

```
Downloading config.json: 100%|███████████████████████████████████████████████████████████████████| 1.47k/1.47k [00:00<00:00, 1.40MB/s]
Downloading pytorch_model.bin: 100%|███████████████████████████████████████████████████████████████| 334M/334M [00:06<00:00, 58.0MB/s]
Downloading tokenizer_config.json: 100%|██████████████████████████████████████████████████████████████| 205/205 [00:00<00:00, 171kB/s]
Downloading vocab.json: 100%|██████████████████████████████████████████████████████████████████████| 941k/941k [00:00<00:00, 5.09MB/s]
Downloading merges.txt: 100%|██████████████████████████████████████████████████████████████████████| 337k/337k [00:00<00:00, 2.30MB/s]
Downloading special_tokens_map.json: 100%|██████████████████████████████████████████████████████████| 99.0/99.0 [00:00<00:00, 100kB/s]
Ask me a question!do you believe in God
Conversation id: 7417a2a5-412b-4117-8dd5-7cf2237d5811 
user >> do you believe in God 
bot >> i don't believe in god, but i do believe in the existence of a god. 

Continue?yes
Ask me a question!what is the meaning of life
Conversation id: 421afd4c-8bcc-400a-8e86-5a97a61685a6 
user >> what is the meaning of life 
bot >> i don't know. i'm not sure. what is the purpose of life?

Continue?no
```

You can exit the conversation anytime by replying "no" to the "Continue" question

## How many models can I run?
- There are lots of pretrained model that you can use:

```
microsoft/DialoGPT-small
microsoft/DialoGPT-medium
microsoft/DialoGPT-large
facebook/blenderbot_small-90M
facebook/blenderbot-400M-distill
facebook/blenderbot-1B-distill

```

or even personal model can be used:

```
vuminhtue/DialoGPT-large-HarryPotter3
rlatt/DialoGPT-large-King-James-Bible-test
```
